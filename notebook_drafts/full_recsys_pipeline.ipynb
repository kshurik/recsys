{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KION DATA\n",
    "INTERACTIONS_PATH = 'https://drive.google.com/file/d/1MomVjEwY2tPJ845zuHeTPt1l53GX2UKd/view?usp=share_link'\n",
    "ITEMS_METADATA_PATH = 'https://drive.google.com/file/d/1XGLUhHpwr0NxU7T4vYNRyaqwSK5HU3N4/view?usp=share_link'\n",
    "USERS_DATA_PATH = 'https://drive.google.com/file/d/1MCTl6hlhFYer1BTwjzIBfdBZdDS_mK8e/view?usp=share_link'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to make it available to download w/o SSL verification\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 1. Helper functions to avoid copy paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_from_gdrive(url, engine: str = 'pyarrow'):\n",
    "    \"\"\"\n",
    "    gets csv data from a given url (taken from file -> share -> copy link)\n",
    "    :url: example https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link\n",
    "    \"\"\"\n",
    "    file_id = url.split('/')[-2]\n",
    "    file_path = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    data = pd.read_parquet(file_path, engine = engine)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Load Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`interactions` dataset shows list of movies that users watched, along with given `total_dur` in seconds and `watched_pct` proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250       72.000\n",
       "1   699317     1659    2021-05-29       8317      100.000\n",
       "2   656683     7107    2021-05-09         10        0.000\n",
       "3   864613     7638    2021-07-05      14483      100.000\n",
       "4   964868     9506    2021-04-30       6725      100.000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interactions data\n",
    "interactions = read_parquet_from_gdrive(INTERACTIONS_PATH)\n",
    "interactions.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`movies_metadata` dataset shows the list of movies existing on OKKO platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>title_orig</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>for_kids</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>studios</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>film</td>\n",
       "      <td>Поговори с ней</td>\n",
       "      <td>Hable con ella</td>\n",
       "      <td>2002.000</td>\n",
       "      <td>драмы, зарубежные, детективы, мелодрамы</td>\n",
       "      <td>Испания</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>None</td>\n",
       "      <td>Педро Альмодовар</td>\n",
       "      <td>Адольфо Фернандес, Ана Фернандес, Дарио Гранди...</td>\n",
       "      <td>Мелодрама легендарного Педро Альмодовара «Пого...</td>\n",
       "      <td>Поговори, ней, 2002, Испания, друзья, любовь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>film</td>\n",
       "      <td>Голые перцы</td>\n",
       "      <td>Search Party</td>\n",
       "      <td>2014.000</td>\n",
       "      <td>зарубежные, приключения, комедии</td>\n",
       "      <td>США</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>None</td>\n",
       "      <td>Скот Армстронг</td>\n",
       "      <td>Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...</td>\n",
       "      <td>Уморительная современная комедия на популярную...</td>\n",
       "      <td>Голые, перцы, 2014, США, друзья, свадьбы, прео...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>film</td>\n",
       "      <td>Тактическая сила</td>\n",
       "      <td>Tactical Force</td>\n",
       "      <td>2011.000</td>\n",
       "      <td>криминал, зарубежные, триллеры, боевики, комедии</td>\n",
       "      <td>Канада</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>None</td>\n",
       "      <td>Адам П. Калтраро</td>\n",
       "      <td>Адриан Холмс, Даррен Шалави, Джерри Вассерман,...</td>\n",
       "      <td>Профессиональный рестлер Стив Остин («Все или ...</td>\n",
       "      <td>Тактическая, сила, 2011, Канада, бандиты, ганг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id content_type             title      title_orig  release_year  \\\n",
       "0    10711         film    Поговори с ней  Hable con ella      2002.000   \n",
       "1     2508         film       Голые перцы    Search Party      2014.000   \n",
       "2    10716         film  Тактическая сила  Tactical Force      2011.000   \n",
       "\n",
       "                                             genres countries  for_kids  \\\n",
       "0           драмы, зарубежные, детективы, мелодрамы   Испания       NaN   \n",
       "1                  зарубежные, приключения, комедии       США       NaN   \n",
       "2  криминал, зарубежные, триллеры, боевики, комедии    Канада       NaN   \n",
       "\n",
       "   age_rating studios         directors  \\\n",
       "0      16.000    None  Педро Альмодовар   \n",
       "1      16.000    None    Скот Армстронг   \n",
       "2      16.000    None  Адам П. Калтраро   \n",
       "\n",
       "                                              actors  \\\n",
       "0  Адольфо Фернандес, Ана Фернандес, Дарио Гранди...   \n",
       "1  Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...   \n",
       "2  Адриан Холмс, Даррен Шалави, Джерри Вассерман,...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Мелодрама легендарного Педро Альмодовара «Пого...   \n",
       "1  Уморительная современная комедия на популярную...   \n",
       "2  Профессиональный рестлер Стив Остин («Все или ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  Поговори, ней, 2002, Испания, друзья, любовь, ...  \n",
       "1  Голые, перцы, 2014, США, друзья, свадьбы, прео...  \n",
       "2  Тактическая, сила, 2011, Канада, бандиты, ганг...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information about films etc\n",
    "movies_metadata = read_parquet_from_gdrive(ITEMS_METADATA_PATH)\n",
    "movies_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973171</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>М</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047345</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        age        income sex  kids_flg\n",
       "0   973171  age_25_34  income_60_90   М         1\n",
       "1   962099  age_18_24  income_20_40   М         0\n",
       "2  1047345  age_45_54  income_40_60   Ж         0\n",
       "3   721985  age_45_54  income_20_40   Ж         0\n",
       "4   704055  age_35_44  income_60_90   Ж         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_data = read_parquet_from_gdrive(USERS_DATA_PATH)\n",
    "users_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Train/test split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data preparation using LightFM Dataset (first-level model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use implicit kNN method `fit` we need a sparse matrix in COOrdinate format. To achieve that we will use `scipy.sparse.coo_matrix` from scipy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundant data points\n",
    "interactions_filtered = interactions.loc[interactions['total_dur'] > 300].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476251, 5) (4195689, 5)\n"
     ]
    }
   ],
   "source": [
    "print(interactions.shape, interactions_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_filtered['last_watch_dt'] = pd.to_datetime(interactions_filtered['last_watch_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min date in filtered interactions: 2021-08-22 00:00:00\n",
      "max date in filtered interactions:: 2021-03-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# set dates params for filter\n",
    "MAX_DATE = interactions_filtered['last_watch_dt'].max()\n",
    "MIN_DATE = interactions_filtered['last_watch_dt'].min()\n",
    "TEST_INTERVAL_DAYS = 14\n",
    "\n",
    "print(f\"min date in filtered interactions: {MAX_DATE}\")\n",
    "print(f\"max date in filtered interactions:: {MIN_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MAX_DATE = MAX_DATE - dt.timedelta(days = TEST_INTERVAL_DAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3530674, 5) (665015, 5)\n"
     ]
    }
   ],
   "source": [
    "# define global train and test\n",
    "global_train = interactions_filtered.loc[interactions_filtered['last_watch_dt'] < TEST_MAX_DATE]\n",
    "global_test = interactions_filtered.loc[interactions_filtered['last_watch_dt'] >= TEST_MAX_DATE]\n",
    "\n",
    "print(global_train.shape, global_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# now, we define \"local\" train and test to use some part of the global train for ranker\n",
    "local_train_thresh = global_train['last_watch_dt'].quantile(q = .7, interpolation = 'nearest')\n",
    "print(local_train_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train = global_train.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2451040, 5) (1079183, 5)\n"
     ]
    }
   ],
   "source": [
    "local_train = global_train.loc[global_train['last_watch_dt'] < local_train_thresh]\n",
    "local_test = global_train.loc[global_train['last_watch_dt'] >= local_train_thresh]\n",
    "\n",
    "print(local_train.shape, local_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579382, 5)\n"
     ]
    }
   ],
   "source": [
    "# finally, we will focus on warm start -- remove cold start users\n",
    "local_test = local_test.loc[local_test['user_id'].isin(local_train['user_id'].unique())]\n",
    "print(local_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init class\n",
    "dataset = Dataset()\n",
    "\n",
    "# fit tuple of user and movie interactions\n",
    "dataset.fit(local_train['user_id'].unique(), local_train['item_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we define lightfm mapper to use it later for checks\n",
    "lightfm_mapping = dataset.mapping()\n",
    "# lightfm_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user mapper length -  539173\n",
      "user features mapper length -  539173\n",
      "movies mapper length -  13006\n",
      "Users movie features mapper length -  13006\n"
     ]
    }
   ],
   "source": [
    "lightfm_mapping = {\n",
    "    'users_mapping': lightfm_mapping[0],\n",
    "    'user_features_mapping': lightfm_mapping[1],\n",
    "    'items_mapping': lightfm_mapping[2],\n",
    "    'item_features_mapping': lightfm_mapping[3],\n",
    "}\n",
    "print('user mapper length - ', len(lightfm_mapping['users_mapping']))\n",
    "print('user features mapper length - ', len(lightfm_mapping['user_features_mapping']))\n",
    "print('movies mapper length - ', len(lightfm_mapping['items_mapping']))\n",
    "print('Users movie features mapper length - ', len(lightfm_mapping['item_features_mapping']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create inverted mappers to check recommendations later\n",
    "lightfm_mapping['users_inv_mapping'] = {v: k for k, v in lightfm_mapping['users_mapping'].items()}\n",
    "lightfm_mapping['items_inv_mapping'] = {v: k for k, v in lightfm_mapping['items_mapping'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special iterator to use with lightfm\n",
    "def df_to_tuple_iterator(df: pd.DataFrame):\n",
    "    '''\n",
    "    :df: pd.DataFrame, interactions dataframe\n",
    "    returs iterator\n",
    "    '''\n",
    "    return zip(*df.values.T)\n",
    "\n",
    "def concat_last_to_list(t):\n",
    "    return (t[0], list(t[1:])[0])\n",
    "\n",
    "def df_to_tuple_list_iterator(df):\n",
    "    return map(concat_last_to_list, zip(*df.values.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train set on the whole interactions dataset (as HW you will have to split into test and train for evaluation)\n",
    "train_mat, train_mat_weights = dataset.build_interactions(df_to_tuple_iterator(local_train[['user_id', 'item_id']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<539173x13006 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 2451040 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<539173x13006 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 2451040 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Train LigthFM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "NO_COMPONENTS = 64\n",
    "LEARNING_RATE = .03\n",
    "LOSS = 'warp'\n",
    "MAX_SAMPLED = 5\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "lfm_model = LightFM(\n",
    "    no_components = NO_COMPONENTS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    loss = LOSS,\n",
    "    max_sampled = MAX_SAMPLED,\n",
    "    random_state = RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:54<00:00,  2.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# execute training\n",
    "for _ in tqdm(range(EPOCHS), total = EPOCHS):\n",
    "    lfm_model.fit_partial(\n",
    "        train_mat,\n",
    "        num_threads = 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekko for user 713676, row number in matrix - 62\n"
     ]
    }
   ],
   "source": [
    "# let's make sense-check\n",
    "top_N = 10\n",
    "user_id = local_train['user_id'][100]\n",
    "row_id = lightfm_mapping['users_mapping'][user_id]\n",
    "print(f'Rekko for user {user_id}, row number in matrix - {row_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13006"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols = list(lightfm_mapping['items_mapping'].values())\n",
    "len(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.2222135,  1.4464369, -1.9280975, ..., -2.1294303, -1.9549031,\n",
       "        -2.0654202], dtype=float32),\n",
       " (13006,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lfm_model.predict(\n",
    "    row_id,\n",
    "    all_cols,\n",
    "    num_threads = 4)\n",
    "pred, pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87,   5, 298, 506, 435, 302,  20, 168, 146, 675])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cols = np.argpartition(pred, -np.arange(top_N))[-top_N:][::-1]\n",
    "top_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate mapper for movieId and title names\n",
    "item_name_mapper = dict(zip(movies_metadata['item_id'], movies_metadata['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>16166</td>\n",
       "      <td>Зверополис</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7571</td>\n",
       "      <td>100% волк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298</td>\n",
       "      <td>13915</td>\n",
       "      <td>Вперёд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506</td>\n",
       "      <td>10761</td>\n",
       "      <td>Моана</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>435</td>\n",
       "      <td>13018</td>\n",
       "      <td>Король лев (2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>302</td>\n",
       "      <td>12173</td>\n",
       "      <td>Мстители: Финал</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>7626</td>\n",
       "      <td>Мстители: Война бесконечности</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>168</td>\n",
       "      <td>3182</td>\n",
       "      <td>Ральф против Интернета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>146</td>\n",
       "      <td>11310</td>\n",
       "      <td>Аладдин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>675</td>\n",
       "      <td>13159</td>\n",
       "      <td>Рататуй</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_id  item_id                          title\n",
       "0      87    16166                     Зверополис\n",
       "1       5     7571                      100% волк\n",
       "2     298    13915                         Вперёд\n",
       "3     506    10761                          Моана\n",
       "4     435    13018              Король лев (2019)\n",
       "5     302    12173                Мстители: Финал\n",
       "6      20     7626  Мстители: Война бесконечности\n",
       "7     168     3182         Ральф против Интернета\n",
       "8     146    11310                        Аладдин\n",
       "9     675    13159                        Рататуй"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.DataFrame({'col_id': top_cols})\n",
    "recs['item_id'] = recs['col_id'].map(lightfm_mapping['items_inv_mapping'].get)\n",
    "recs['title'] = recs['item_id'].map(item_name_mapper)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekko for user 869219, row number in matrix - 675\n"
     ]
    }
   ],
   "source": [
    "# let's make sense-check\n",
    "top_N = 10\n",
    "user_id = local_train['user_id'][1000]\n",
    "row_id = lightfm_mapping['users_mapping'][user_id]\n",
    "print(f'Rekko for user {user_id}, row number in matrix - {row_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.19702657, -0.38245714, -2.658608  , ..., -3.2753859 ,\n",
       "        -3.0609252 , -2.8367202 ], dtype=float32),\n",
       " (13006,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lfm_model.predict(\n",
    "    row_id,\n",
    "    all_cols,\n",
    "    num_threads = 4)\n",
    "pred, pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 222,  682,   52,  207,  962,  333, 2935, 2059,  306, 5235])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cols = np.argpartition(pred, -np.arange(top_N))[-top_N:][::-1]\n",
    "top_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222</td>\n",
       "      <td>676</td>\n",
       "      <td>Человек-невидимка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>682</td>\n",
       "      <td>16361</td>\n",
       "      <td>Doom: Аннигиляция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>2647</td>\n",
       "      <td>Идеальный пациент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207</td>\n",
       "      <td>11143</td>\n",
       "      <td>На пятьдесят оттенков темнее</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>962</td>\n",
       "      <td>9335</td>\n",
       "      <td>Подводная братва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>333</td>\n",
       "      <td>4141</td>\n",
       "      <td>Пятьдесят оттенков серого</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2935</td>\n",
       "      <td>1090</td>\n",
       "      <td>Нерождённый</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2059</td>\n",
       "      <td>10647</td>\n",
       "      <td>Винчестер. Дом, который построили призраки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>306</td>\n",
       "      <td>9169</td>\n",
       "      <td>Взаперти</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5235</td>\n",
       "      <td>13948</td>\n",
       "      <td>Смерть ей к лицу</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_id  item_id                                       title\n",
       "0     222      676                           Человек-невидимка\n",
       "1     682    16361                           Doom: Аннигиляция\n",
       "2      52     2647                           Идеальный пациент\n",
       "3     207    11143                На пятьдесят оттенков темнее\n",
       "4     962     9335                            Подводная братва\n",
       "5     333     4141                   Пятьдесят оттенков серого\n",
       "6    2935     1090                                 Нерождённый\n",
       "7    2059    10647  Винчестер. Дом, который построили призраки\n",
       "8     306     9169                                    Взаперти\n",
       "9    5235    13948                            Смерть ей к лицу"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.DataFrame({'col_id': top_cols})\n",
    "recs['item_id'] = recs['col_id'].map(lightfm_mapping['items_inv_mapping'].get)\n",
    "recs['title'] = recs['item_id'].map(item_name_mapper)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144739"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make predictions for all users in test\n",
    "test_preds = pd.DataFrame({\n",
    "    'user_id': local_test['user_id'].unique()\n",
    "})\n",
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_recs = pd.DataFrame()\n",
    "# for user in tqdm(users_mapping.keys()):\n",
    "#     row_id = users_mapping[user]\n",
    "#     pred = lfm_model.predict(\n",
    "#         row_id,\n",
    "#         all_cols,\n",
    "#         num_threads = 4)\n",
    "#     top_cols = np.argpartition(pred, -np.arange(top_N))[-top_N:][::-1]\n",
    "#     user_recs = pd.DataFrame({'col_id': top_cols})\n",
    "#     user_recs['item_id'] = user_recs['col_id'].map(lightfm_mapping['items_inv_mapping'].get)\n",
    "#     user_recs['title'] = user_recs['item_id'].map(item_name_mapper)\n",
    "\n",
    "#     all_recs = pd.concat([all_recs, user_recs], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lightfm_recs_mapper(\n",
    "        model: object,\n",
    "        item_ids: list,\n",
    "        known_items: dict,\n",
    "        user_features: list,\n",
    "        item_features: list,\n",
    "        N: int,\n",
    "        user_mapping: dict,\n",
    "        item_inv_mapping: dict,\n",
    "        num_threads: int = 4\n",
    "        ):\n",
    "    def _recs_mapper(user):\n",
    "        user_id = user_mapping[user]\n",
    "        recs = model.predict(\n",
    "            user_id,\n",
    "            item_ids,\n",
    "            user_features = user_features,\n",
    "            item_features = item_features,\n",
    "            num_threads = num_threads)\n",
    "        \n",
    "        additional_N = len(known_items[user_id]) if user_id in known_items else 0\n",
    "        total_N = N + additional_N\n",
    "        top_cols = np.argpartition(recs, -np.arange(total_N))[-total_N:][::-1]\n",
    "        \n",
    "        final_recs = [item_inv_mapping[item] for item in top_cols]\n",
    "        if additional_N > 0:\n",
    "            filter_items = known_items[user_id]\n",
    "            final_recs = [item for item in final_recs if item not in filter_items]\n",
    "        return final_recs[:N]\n",
    "    return _recs_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = generate_lightfm_recs_mapper(\n",
    "    lfm_model, \n",
    "    item_ids = all_cols, \n",
    "    known_items = dict(),\n",
    "    N = top_N,\n",
    "    user_features = None, \n",
    "    item_features = None, \n",
    "    user_mapping = lightfm_mapping['users_mapping'],\n",
    "    item_inv_mapping = lightfm_mapping['items_inv_mapping'],\n",
    "    num_threads = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds['item_id'] = test_preds['user_id'].map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds.explode('item_id')\n",
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds['rank'] = test_preds.groupby('user_id').cumcount() + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds['item_name'] = test_preds['item_id'].map(item_name_mapper)\n",
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sense check for diversity of recommendations\n",
    "test_preds.item_id.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. CatBoostClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1. Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to creat 0/1 as indication of interaction:\n",
    "\n",
    "- positive event -- 1, if watch_pct is not null;\n",
    "- negative venet -- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_preds = pd.merge(test_preds, local_test, how = 'inner', on = ['user_id', 'item_id'])\n",
    "positive_preds['target'] = 1\n",
    "positive_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_preds = pd.merge(test_preds, local_test, how = 'left', on = ['user_id', 'item_id'])\n",
    "negative_preds = negative_preds.loc[negative_preds['watched_pct'].isnull()].sample(frac = .2)\n",
    "negative_preds['target'] = 0\n",
    "negative_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random split to train ranker\n",
    "train_users, test_users = train_test_split(\n",
    "    local_test['user_id'].unique(),\n",
    "    test_size = .2,\n",
    "    random_state = 13\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_train_set = shuffle(\n",
    "    pd.concat(\n",
    "    [positive_preds.loc[positive_preds['user_id'].isin(train_users)],\n",
    "    negative_preds.loc[negative_preds['user_id'].isin(train_users)]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_test_set = shuffle(\n",
    "    pd.concat(\n",
    "    [positive_preds.loc[positive_preds['user_id'].isin(test_users)],\n",
    "    negative_preds.loc[negative_preds['user_id'].isin(test_users)]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TRAIN: {cbm_train_set.describe()} \\n, TEST: {cbm_test_set.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this tutorial, I will not do any feature aggregation - use default ones from data\n",
    "USER_FEATURES = ['age', 'income', 'sex', 'kids_flg']\n",
    "ITEM_FEATURES = ['content_type', 'release_year', 'for_kids', 'age_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins user features\n",
    "cbm_train_set = pd.merge(cbm_train_set, users_data[['user_id'] + USER_FEATURES],\n",
    "                         how = 'left', on = ['user_id'])\n",
    "cbm_test_set = pd.merge(cbm_test_set, users_data[['user_id'] + USER_FEATURES],\n",
    "                        how = 'left', on = ['user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins item features\n",
    "cbm_train_set = pd.merge(cbm_train_set, movies_metadata[['item_id'] + ITEM_FEATURES],\n",
    "                         how = 'left', on = ['item_id'])\n",
    "cbm_test_set = pd.merge(cbm_test_set, movies_metadata[['item_id'] + ITEM_FEATURES],\n",
    "                        how = 'left', on = ['item_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cbm_train_set.shape, cbm_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS = ['user_id', 'item_id']\n",
    "TARGET = ['target']\n",
    "CATEGORICAL_COLS = ['age', 'income', 'sex', 'content_type']\n",
    "DROP_COLS = ['item_name', 'last_watch_dt', 'watched_pct', 'total_dur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cbm_train_set.drop(ID_COLS + DROP_COLS + TARGET, axis = 1), cbm_train_set[TARGET]\n",
    "X_test, y_test = cbm_test_set.drop(ID_COLS + DROP_COLS + TARGET, axis = 1), cbm_test_set[TARGET]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(X_train.mode().iloc[0])\n",
    "X_test = X_test.fillna(X_test.mode().iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_classifier = CatBoostClassifier(\n",
    "    loss_function = 'CrossEntropy',\n",
    "    iterations = 5000,\n",
    "    learning_rate = .1,\n",
    "    depth = 6,\n",
    "    random_state = 1234,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    early_stopping_rounds = 100, # to avoid overfitting,\n",
    "    cat_features = CATEGORICAL_COLS \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.3. Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make basic shapley plot to investigate feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(cbm_classifier)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, show = False, color_bar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test\n",
    "y_test_pred = cbm_classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(f\"ROC AUC score = {roc_auc_score(y_test, y_test_pred[:, 1]):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source & further readings\n",
    "- [Kaggle notebook from MTS RecSys cours](https://www.kaggle.com/code/sharthz23/implicit-lightfm/notebook)\n",
    "- [Hybrid Approach](https://github.com/sharthZ23/your-second-recsys/blob/master/lecture_5/tutorial_hybrid_model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
