{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d826d",
   "metadata": {},
   "source": [
    "(chapter1_part7)=\n",
    "\n",
    "# Full Pipeline of the Two-level Recommender System\n",
    "\n",
    "In this chapter, we will wrap up all steps from 1.2 to 1.5:\n",
    "- Preprocess data with proper two-level validation;\n",
    "- Develop candidate generation model with implicit library;\n",
    "- Then, move to Catboost and get our reranker - second level model;\n",
    "- Finally, evaluate our models: implicit vs implicit + reranker\n",
    "\n",
    "First, let's recall what we discussed in [`Metrics & Validation`](https://rekkobook.com/chapter1/validation_metrics.html)\n",
    "In recommender systems we have special data split to validate our model - we split data by time for candidates\n",
    "and by users for reranker. Now, we move on to coding.\n",
    "\n",
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c75772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KION DATA\n",
    "INTERACTIONS_PATH = 'https://drive.google.com/file/d/1MomVjEwY2tPJ845zuHeTPt1l53GX2UKd/view?usp=share_link'\n",
    "ITEMS_METADATA_PATH = 'https://drive.google.com/file/d/1XGLUhHpwr0NxU7T4vYNRyaqwSK5HU3N4/view?usp=share_link'\n",
    "USERS_DATA_PATH = 'https://drive.google.com/file/d/1MCTl6hlhFYer1BTwjzIBfdBZdDS_mK8e/view?usp=share_link'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a4047",
   "metadata": {},
   "source": [
    "# 1. Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52902c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/.cache/pypoetry/virtualenvs/rekko-handbook-y_Nwlfrq-py3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    }
   ],
   "source": [
    "# just to make it available to download w/o SSL verification\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b6abc",
   "metadata": {},
   "source": [
    "## 1. 1. Helper functions to avoid copy paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe2e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_from_gdrive(url, engine: str = 'pyarrow'):\n",
    "    \"\"\"\n",
    "    gets csv data from a given url (taken from file -> share -> copy link)\n",
    "    :url: example https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link\n",
    "    \"\"\"\n",
    "    file_id = url.split('/')[-2]\n",
    "    file_path = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    data = pd.read_parquet(file_path, engine = engine)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e615313",
   "metadata": {},
   "source": [
    "# 2. Main\n",
    "## 2.1. Load and preprocess data\n",
    "`interactions` dataset shows list of movies that users watched, along with given `total_dur` in seconds and `watched_pct` proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f03b333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>72.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656683</td>\n",
       "      <td>7107</td>\n",
       "      <td>2021-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964868</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>6725</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct\n",
       "0   176549     9506    2021-05-11       4250       72.000\n",
       "1   699317     1659    2021-05-29       8317      100.000\n",
       "2   656683     7107    2021-05-09         10        0.000\n",
       "3   864613     7638    2021-07-05      14483      100.000\n",
       "4   964868     9506    2021-04-30       6725      100.000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interactions data\n",
    "interactions = read_parquet_from_gdrive(INTERACTIONS_PATH)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae99cfd",
   "metadata": {},
   "source": [
    "`movies_metadata` dataset shows the list of movies existing on OKKO platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5946223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>title_orig</th>\n",
       "      <th>release_year</th>\n",
       "      <th>genres</th>\n",
       "      <th>countries</th>\n",
       "      <th>for_kids</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>studios</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>film</td>\n",
       "      <td>Поговори с ней</td>\n",
       "      <td>Hable con ella</td>\n",
       "      <td>2002.000</td>\n",
       "      <td>драмы, зарубежные, детективы, мелодрамы</td>\n",
       "      <td>Испания</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>None</td>\n",
       "      <td>Педро Альмодовар</td>\n",
       "      <td>Адольфо Фернандес, Ана Фернандес, Дарио Гранди...</td>\n",
       "      <td>Мелодрама легендарного Педро Альмодовара «Пого...</td>\n",
       "      <td>Поговори, ней, 2002, Испания, друзья, любовь, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2508</td>\n",
       "      <td>film</td>\n",
       "      <td>Голые перцы</td>\n",
       "      <td>Search Party</td>\n",
       "      <td>2014.000</td>\n",
       "      <td>зарубежные, приключения, комедии</td>\n",
       "      <td>США</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>None</td>\n",
       "      <td>Скот Армстронг</td>\n",
       "      <td>Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...</td>\n",
       "      <td>Уморительная современная комедия на популярную...</td>\n",
       "      <td>Голые, перцы, 2014, США, друзья, свадьбы, прео...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>film</td>\n",
       "      <td>Тактическая сила</td>\n",
       "      <td>Tactical Force</td>\n",
       "      <td>2011.000</td>\n",
       "      <td>криминал, зарубежные, триллеры, боевики, комедии</td>\n",
       "      <td>Канада</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000</td>\n",
       "      <td>None</td>\n",
       "      <td>Адам П. Калтраро</td>\n",
       "      <td>Адриан Холмс, Даррен Шалави, Джерри Вассерман,...</td>\n",
       "      <td>Профессиональный рестлер Стив Остин («Все или ...</td>\n",
       "      <td>Тактическая, сила, 2011, Канада, бандиты, ганг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id content_type             title      title_orig  release_year  \\\n",
       "0    10711         film    Поговори с ней  Hable con ella      2002.000   \n",
       "1     2508         film       Голые перцы    Search Party      2014.000   \n",
       "2    10716         film  Тактическая сила  Tactical Force      2011.000   \n",
       "\n",
       "                                             genres countries  for_kids  \\\n",
       "0           драмы, зарубежные, детективы, мелодрамы   Испания       NaN   \n",
       "1                  зарубежные, приключения, комедии       США       NaN   \n",
       "2  криминал, зарубежные, триллеры, боевики, комедии    Канада       NaN   \n",
       "\n",
       "   age_rating studios         directors  \\\n",
       "0      16.000    None  Педро Альмодовар   \n",
       "1      16.000    None    Скот Армстронг   \n",
       "2      16.000    None  Адам П. Калтраро   \n",
       "\n",
       "                                              actors  \\\n",
       "0  Адольфо Фернандес, Ана Фернандес, Дарио Гранди...   \n",
       "1  Адам Палли, Брайан Хаски, Дж.Б. Смув, Джейсон ...   \n",
       "2  Адриан Холмс, Даррен Шалави, Джерри Вассерман,...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Мелодрама легендарного Педро Альмодовара «Пого...   \n",
       "1  Уморительная современная комедия на популярную...   \n",
       "2  Профессиональный рестлер Стив Остин («Все или ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  Поговори, ней, 2002, Испания, друзья, любовь, ...  \n",
       "1  Голые, перцы, 2014, США, друзья, свадьбы, прео...  \n",
       "2  Тактическая, сила, 2011, Канада, бандиты, ганг...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information about films etc\n",
    "movies_metadata = read_parquet_from_gdrive(ITEMS_METADATA_PATH)\n",
    "movies_metadata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc716763",
   "metadata": {},
   "source": [
    "`users_data` contains basic info like gender, age group, income group and kids flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d500414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973171</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>М</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047345</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        age        income sex  kids_flg\n",
       "0   973171  age_25_34  income_60_90   М         1\n",
       "1   962099  age_18_24  income_20_40   М         0\n",
       "2  1047345  age_45_54  income_40_60   Ж         0\n",
       "3   721985  age_45_54  income_20_40   Ж         0\n",
       "4   704055  age_35_44  income_60_90   Ж         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_data = read_parquet_from_gdrive(USERS_DATA_PATH)\n",
    "users_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044501b",
   "metadata": {},
   "source": [
    "Now, a bit of preprocessing to avoid noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f4ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476251, 5) (4195689, 5)\n"
     ]
    }
   ],
   "source": [
    "# remove redundant data points\n",
    "interactions_filtered = interactions.loc[interactions['total_dur'] > 300].reset_index(drop = True)\n",
    "print(interactions.shape, interactions_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "914fc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime\n",
    "interactions_filtered['last_watch_dt'] = pd.to_datetime(interactions_filtered['last_watch_dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ed1b2",
   "metadata": {},
   "source": [
    "### 2.1.2. Train / Test split\n",
    "\n",
    "As we dicussed in Validation and metrics [chapter], we need time based split for candidates generation\n",
    "to avoid look-ahead bias. Therefor, let's set date thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a922a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min date in filtered interactions: 2021-08-22 00:00:00\n",
      "max date in filtered interactions:: 2021-03-13 00:00:00\n",
      "test max date to split:: 2021-08-08 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# set dates params for filter\n",
    "MAX_DATE = interactions_filtered['last_watch_dt'].max()\n",
    "MIN_DATE = interactions_filtered['last_watch_dt'].min()\n",
    "TEST_INTERVAL_DAYS = 14\n",
    "TEST_MAX_DATE = MAX_DATE - dt.timedelta(days = TEST_INTERVAL_DAYS)\n",
    "\n",
    "print(f\"min date in filtered interactions: {MAX_DATE}\")\n",
    "print(f\"max date in filtered interactions:: {MIN_DATE}\")\n",
    "print(f\"test max date to split:: {TEST_MAX_DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26a188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3530223, 5) (665015, 5)\n"
     ]
    }
   ],
   "source": [
    "# define global train and test\n",
    "global_train = interactions_filtered.loc[interactions_filtered['last_watch_dt'] < TEST_MAX_DATE]\n",
    "global_test = interactions_filtered.loc[interactions_filtered['last_watch_dt'] >= TEST_MAX_DATE]\n",
    "\n",
    "global_train = global_train.dropna().reset_index(drop = True)\n",
    "print(global_train.shape, global_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18695dd1",
   "metadata": {},
   "source": [
    "Here, we define \"local\" train and test to use some part of the global train for ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01240376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "local_train_thresh = global_train['last_watch_dt'].quantile(q = .7, interpolation = 'nearest')\n",
    "\n",
    "print(local_train_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeea0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2451040, 5) (1079183, 5)\n"
     ]
    }
   ],
   "source": [
    "local_train = global_train.loc[global_train['last_watch_dt'] < local_train_thresh]\n",
    "local_test = global_train.loc[global_train['last_watch_dt'] >= local_train_thresh]\n",
    "\n",
    "print(local_train.shape, local_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d947ec",
   "metadata": {},
   "source": [
    "Final filter, we will focus on warm start -- remove cold start users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fc25ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579382, 5)\n"
     ]
    }
   ],
   "source": [
    "local_test = local_test.loc[local_test['user_id'].isin(local_train['user_id'].unique())]\n",
    "print(local_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb997a12",
   "metadata": {},
   "source": [
    "### 2.1.2 LightFM Dataset setup\n",
    "LightFM provides built-in Dataset class to work with and use in fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ae8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init class\n",
    "dataset = Dataset()\n",
    "\n",
    "# fit tuple of user and movie interactions\n",
    "dataset.fit(local_train['user_id'].unique(), local_train['item_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac473bc5",
   "metadata": {},
   "source": [
    "Next, we will need mappers as usual, but with lightfm everything is easier and can be\n",
    "extracted from initiated data class `dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81221ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user mapper length -  539173\n",
      "user features mapper length -  539173\n",
      "movies mapper length -  13006\n",
      "Users movie features mapper length -  13006\n"
     ]
    }
   ],
   "source": [
    "# now, we define lightfm mapper to use it later for checks\n",
    "lightfm_mapping = dataset.mapping()\n",
    "lightfm_mapping = {\n",
    "    'users_mapping': lightfm_mapping[0],\n",
    "    'user_features_mapping': lightfm_mapping[1],\n",
    "    'items_mapping': lightfm_mapping[2],\n",
    "    'item_features_mapping': lightfm_mapping[3],\n",
    "}\n",
    "print('user mapper length - ', len(lightfm_mapping['users_mapping']))\n",
    "print('user features mapper length - ', len(lightfm_mapping['user_features_mapping']))\n",
    "print('movies mapper length - ', len(lightfm_mapping['items_mapping']))\n",
    "print('Users movie features mapper length - ', len(lightfm_mapping['item_features_mapping']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb3b65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverted mappers to check recommendations\n",
    "lightfm_mapping['users_inv_mapping'] = {v: k for k, v in lightfm_mapping['users_mapping'].items()}\n",
    "lightfm_mapping['items_inv_mapping'] = {v: k for k, v in lightfm_mapping['items_mapping'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52fe7748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate mapper for movie_id and title names\n",
    "item_name_mapper = dict(zip(movies_metadata['item_id'], movies_metadata['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983c44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special iterator to use with lightfm\n",
    "def df_to_tuple_iterator(df: pd.DataFrame):\n",
    "    '''\n",
    "    :df: pd.DataFrame, interactions dataframe\n",
    "    returs iterator\n",
    "    '''\n",
    "    return zip(*df.values.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de14a4",
   "metadata": {},
   "source": [
    "Finally, built dataset using `user_id` & `item_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1798d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train set on the whole interactions dataset (as HW you will have to split into test and train for evaluation)\n",
    "train_mat, train_mat_weights = dataset.build_interactions(df_to_tuple_iterator(local_train[['user_id', 'item_id']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2442b517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<539173x13006 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 2451040 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6af1caa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<539173x13006 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 2451040 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c30c38",
   "metadata": {},
   "source": [
    "## 2.2. Fit the model\n",
    "\n",
    "Set some default parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "470debd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "NO_COMPONENTS = 64\n",
    "LEARNING_RATE = .03\n",
    "LOSS = 'warp'\n",
    "MAX_SAMPLED = 5\n",
    "RANDOM_STATE = 42\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "995a91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "lfm_model = LightFM(\n",
    "    no_components = NO_COMPONENTS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    loss = LOSS,\n",
    "    max_sampled = MAX_SAMPLED,\n",
    "    random_state = RANDOM_STATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0916a01f",
   "metadata": {},
   "source": [
    "Run training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "527099b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:04<01:28,  4.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:07<01:06,  3.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:10<00:55,  3.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:12<00:47,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:15<00:42,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:18<00:38,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:20<00:33,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:22<00:30,  2.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:25<00:27,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:27<00:24,  2.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:29<00:21,  2.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [00:31<00:18,  2.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [00:33<00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [00:36<00:13,  2.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [00:38<00:10,  2.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [00:40<00:08,  2.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [00:42<00:06,  2.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [00:44<00:04,  2.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [00:46<00:02,  2.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [00:48<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [00:48<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# execute training\n",
    "for _ in tqdm(range(EPOCHS), total = EPOCHS):\n",
    "    lfm_model.fit_partial(\n",
    "        train_mat,\n",
    "        num_threads = 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0289b8",
   "metadata": {},
   "source": [
    "Let's make sense-check on the output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eea45438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekko for user 713676, row number in matrix - 62\n"
     ]
    }
   ],
   "source": [
    "top_N = 10\n",
    "user_id = local_train['user_id'][100]\n",
    "row_id = lightfm_mapping['users_mapping'][user_id]\n",
    "print(f'Rekko for user {user_id}, row number in matrix - {row_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5317a797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([298, 168,  87, 294, 933,   5, 435,  20,  55, 560])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item indices\n",
    "all_cols = list(lightfm_mapping['items_mapping'].values())\n",
    "len(all_cols)\n",
    "\n",
    "# predictions\n",
    "pred = lfm_model.predict(\n",
    "    row_id,\n",
    "    all_cols,\n",
    "    num_threads = 4)\n",
    "pred, pred.shape\n",
    "\n",
    "# sort and final postprocessing\n",
    "top_cols = np.argpartition(pred, -np.arange(top_N))[-top_N:][::-1]\n",
    "top_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "808116e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298</td>\n",
       "      <td>13915</td>\n",
       "      <td>Вперёд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168</td>\n",
       "      <td>3182</td>\n",
       "      <td>Ральф против Интернета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>16166</td>\n",
       "      <td>Зверополис</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294</td>\n",
       "      <td>9164</td>\n",
       "      <td>ВАЛЛ-И</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>933</td>\n",
       "      <td>13243</td>\n",
       "      <td>Головоломка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7571</td>\n",
       "      <td>100% волк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>435</td>\n",
       "      <td>13018</td>\n",
       "      <td>Король лев (2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>7626</td>\n",
       "      <td>Мстители: Война бесконечности</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>15719</td>\n",
       "      <td>Семейка Бигфутов</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>560</td>\n",
       "      <td>13935</td>\n",
       "      <td>Гравити Фолз</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_id  item_id                          title\n",
       "0     298    13915                         Вперёд\n",
       "1     168     3182         Ральф против Интернета\n",
       "2      87    16166                     Зверополис\n",
       "3     294     9164                         ВАЛЛ-И\n",
       "4     933    13243                    Головоломка\n",
       "5       5     7571                      100% волк\n",
       "6     435    13018              Король лев (2019)\n",
       "7      20     7626  Мстители: Война бесконечности\n",
       "8      55    15719               Семейка Бигфутов\n",
       "9     560    13935                   Гравити Фолз"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas dataframe for convenience\n",
    "recs = pd.DataFrame({'col_id': top_cols})\n",
    "recs['item_id'] = recs['col_id'].map(lightfm_mapping['items_inv_mapping'].get)\n",
    "recs['title'] = recs['item_id'].map(item_name_mapper)\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a087ce37",
   "metadata": {},
   "source": [
    "In the end, we need to make predictions on all `local_test` users to use this sample to train reranker model.\n",
    "As I have mentioned earlier, in reranker we split randomly by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f49ba7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_test_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# make predictions for all users in test\u001b[39;00m\n\u001b[1;32m      2\u001b[0m local_test_preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mlocal_test_preds\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mlen\u001b[39m(local_test_preds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local_test_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# make predictions for all users in test\n",
    "local_test_preds = pd.DataFrame({\n",
    "    'user_id': local_test_preds['user_id'].unique()\n",
    "})\n",
    "len(local_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lightfm_recs_mapper(\n",
    "        model: object,\n",
    "        item_ids: list,\n",
    "        known_items: dict,\n",
    "        user_features: list,\n",
    "        item_features: list,\n",
    "        N: int,\n",
    "        user_mapping: dict,\n",
    "        item_inv_mapping: dict,\n",
    "        num_threads: int = 4\n",
    "        ):\n",
    "    def _recs_mapper(user):\n",
    "        user_id = user_mapping[user]\n",
    "        recs = model.predict(\n",
    "            user_id,\n",
    "            item_ids,\n",
    "            user_features = user_features,\n",
    "            item_features = item_features,\n",
    "            num_threads = num_threads)\n",
    "        \n",
    "        additional_N = len(known_items[user_id]) if user_id in known_items else 0\n",
    "        total_N = N + additional_N\n",
    "        top_cols = np.argpartition(recs, -np.arange(total_N))[-total_N:][::-1]\n",
    "        \n",
    "        final_recs = [item_inv_mapping[item] for item in top_cols]\n",
    "        if additional_N > 0:\n",
    "            filter_items = known_items[user_id]\n",
    "            final_recs = [item for item in final_recs if item not in filter_items]\n",
    "        return final_recs[:N]\n",
    "    return _recs_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init mapper to get predictions\n",
    "mapper = generate_lightfm_recs_mapper(\n",
    "    lfm_model, \n",
    "    item_ids = all_cols, \n",
    "    known_items = dict(),\n",
    "    N = top_N,\n",
    "    user_features = None, \n",
    "    item_features = None, \n",
    "    user_mapping = lightfm_mapping['users_mapping'],\n",
    "    item_inv_mapping = lightfm_mapping['items_inv_mapping'],\n",
    "    num_threads = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd1c926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "local_test_preds['item_id'] = local_test_preds['user_id'].map(mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3617f9",
   "metadata": {},
   "source": [
    "Prettify predictions to use in catboost - make list to rows and add rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_test_preds = local_test_preds.explode('item_id')\n",
    "local_test_preds['rank'] = local_test_preds.groupby('user_id').cumcount() + 1 \n",
    "local_test_preds['item_name'] = local_test_preds['item_id'].map(item_name_mapper)\n",
    "print(f'Data shape{local_test_preds.shape}')\n",
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd08c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sense check for diversity of recommendations\n",
    "test_preds.item_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec32bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db37f01f",
   "metadata": {},
   "source": [
    "## 2.3. CatBoostClassifier (ReRanker)\n",
    "### 2.3.1. Data preparation\n",
    "\n",
    "We need to creat 0/1 as indication of interaction:\n",
    "\n",
    "- positive event -- 1, if watch_pct is not null;\n",
    "- negative venet -- 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fcddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_preds = pd.merge(test_preds, local_test, how = 'inner', on = ['user_id', 'item_id'])\n",
    "positive_preds['target'] = 1\n",
    "positive_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e147fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_preds = pd.merge(test_preds, local_test, how = 'left', on = ['user_id', 'item_id'])\n",
    "negative_preds = negative_preds.loc[negative_preds['watched_pct'].isnull()].sample(frac = .2)\n",
    "negative_preds['target'] = 0\n",
    "negative_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdab4b7",
   "metadata": {},
   "source": [
    "Random split by users to train reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users, test_users = train_test_split(\n",
    "    local_test['user_id'].unique(),\n",
    "    test_size = .2,\n",
    "    random_state = 13\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2f36f",
   "metadata": {},
   "source": [
    "Set up train/test set and shuffle samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad206ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_train_set = shuffle(\n",
    "    pd.concat(\n",
    "    [positive_preds.loc[positive_preds['user_id'].isin(train_users)],\n",
    "    negative_preds.loc[negative_preds['user_id'].isin(train_users)]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00912df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_test_set = shuffle(\n",
    "    pd.concat(\n",
    "    [positive_preds.loc[positive_preds['user_id'].isin(test_users)],\n",
    "    negative_preds.loc[negative_preds['user_id'].isin(test_users)]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac1d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TRAIN: {cbm_train_set.describe()} \\n, TEST: {cbm_test_set.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dcc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this tutorial, I will not do any feature aggregation - use default ones from data\n",
    "USER_FEATURES = ['age', 'income', 'sex', 'kids_flg']\n",
    "ITEM_FEATURES = ['content_type', 'release_year', 'for_kids', 'age_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea2874",
   "metadata": {},
   "source": [
    "Prepare final datasets - joins user and item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_train_set = pd.merge(cbm_train_set, users_data[['user_id'] + USER_FEATURES],\n",
    "                         how = 'left', on = ['user_id'])\n",
    "cbm_test_set = pd.merge(cbm_test_set, users_data[['user_id'] + USER_FEATURES],\n",
    "                        how = 'left', on = ['user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins item features\n",
    "cbm_train_set = pd.merge(cbm_train_set, movies_metadata[['item_id'] + ITEM_FEATURES],\n",
    "                         how = 'left', on = ['item_id'])\n",
    "cbm_test_set = pd.merge(cbm_test_set, movies_metadata[['item_id'] + ITEM_FEATURES],\n",
    "                        how = 'left', on = ['item_id'])\n",
    "\n",
    "print(cbm_train_set.shape, cbm_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eec366",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4bdf26",
   "metadata": {},
   "source": [
    "Set necessary cols to filter out sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b856013",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COLS = ['user_id', 'item_id']\n",
    "TARGET = ['target']\n",
    "CATEGORICAL_COLS = ['age', 'income', 'sex', 'content_type']\n",
    "DROP_COLS = ['item_name', 'last_watch_dt', 'watched_pct', 'total_dur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe691451",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cbm_train_set.drop(ID_COLS + DROP_COLS + TARGET, axis = 1), cbm_train_set[TARGET]\n",
    "X_test, y_test = cbm_test_set.drop(ID_COLS + DROP_COLS + TARGET, axis = 1), cbm_test_set[TARGET]\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f744030",
   "metadata": {},
   "source": [
    "Fill missing values with mode - just in case by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf077ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(X_train.mode().iloc[0])\n",
    "X_test = X_test.fillna(X_test.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b4ed1",
   "metadata": {},
   "source": [
    "### 2.3.2 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_classifier = CatBoostClassifier(\n",
    "    loss_function = 'CrossEntropy',\n",
    "    iterations = 5000,\n",
    "    learning_rate = .1,\n",
    "    depth = 6,\n",
    "    random_state = 1234,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49994b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_classifier.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    early_stopping_rounds = 100, # to avoid overfitting,\n",
    "    cat_features = CATEGORICAL_COLS,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917526e",
   "metadata": {},
   "source": [
    "### 2.3.3. Model Evaluation\n",
    "Let's make basic shapley plot to investigate feature importance. We expect that `rank` - predicted\n",
    "order from LightFM - must be on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbd847",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(cbm_classifier)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, show = False, color_bar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f706340",
   "metadata": {},
   "source": [
    "Let's see performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61440aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on test\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_test_pred = cbm_classifier.predict_proba(X_test)\n",
    "\n",
    "print(f\"ROC AUC score = {roc_auc_score(y_test, y_test_pred[:, 1]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483f4d1",
   "metadata": {},
   "source": [
    "### 2.4. Evaluation on global test\n",
    "Here, compare predictions of two models - LightFM vs LightFM + CatBoost.\n",
    "First, let's calculate predictions from both models - here we generate candidates via LightFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dded366",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_test_predictions = pd.DataFrame({\n",
    "    'user_id': global_test['user_id'].unique()\n",
    "        }\n",
    "    )\n",
    "\n",
    "# filter out cold start users\n",
    "global_test_predictions = global_test_predictions.loc[global_test_predictions['user_id'].isin(local_train.user_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53906ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set param for number of candidates\n",
    "top_k = 100\n",
    "\n",
    "# generate list of watched titles to filter\n",
    "watched_movies = local_train.groupby('user_id')['item_id'].apply(list).to_dict()\n",
    "\n",
    "mapper = generate_lightfm_recs_mapper(\n",
    "    lfm_model, \n",
    "    item_ids = all_cols, \n",
    "    known_items = watched_movies,\n",
    "    N = top_k,\n",
    "    user_features = None, \n",
    "    item_features = None, \n",
    "    user_mapping = lightfm_mapping['users_mapping'],\n",
    "    item_inv_mapping = lightfm_mapping['items_inv_mapping'],\n",
    "    num_threads = 10\n",
    ")\n",
    "\n",
    "global_test_predictions['item_id'] = global_test_predictions['user_id'].map(mapper)\n",
    "global_test_predictions = global_test_predictions.explode('item_id').reset_index(drop=True)\n",
    "global_test_predictions['rank'] = global_test_predictions.groupby('user_id').cumcount() + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022f4b1",
   "metadata": {},
   "source": [
    "Now, we can move to reranker to make predictions and make new order.\n",
    "Beforehand, we need to prepare data for reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_global_test = pd.merge(global_test_predictions, users_data[['user_id'] + USER_FEATURES],\n",
    "                         how = 'left', on = ['user_id'])\n",
    "\n",
    "cbm_global_test = pd.merge(cbm_global_test, movies_metadata[['item_id'] + ITEM_FEATURES],\n",
    "                         how = 'left', on = ['item_id'])\n",
    "cbm_global_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344cf73",
   "metadata": {},
   "source": [
    "Fill missing values with the most frequent values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5be09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_global_test = cbm_global_test.fillna(cbm_global_test.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4202c7",
   "metadata": {},
   "source": [
    "Predict scores to get ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3959cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm_global_test['cbm_preds'] = cbm_classifier.predict_proba(cbm_global_test[X_train.columns])[:, 1]\n",
    "cbm_global_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cbm rank\n",
    "cbm_global_test = cbm_global_test.sort_values(by = ['user_id', 'cbm_preds'], ascending = [True, False])\n",
    "cbm_global_test['cbm_rank'] = cbm_global_test.groupby('user_id').cumcount() + 1\n",
    "cbm_global_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f67a2",
   "metadata": {},
   "source": [
    "Finally, let's move on to comparison\n",
    "- define function to calculate matrix-based metrics;\n",
    "- create table of metrics for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df504cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(df_true, df_pred, k: int = 10, target_col = 'rank'):\n",
    "    \"\"\"\n",
    "    calculates confusion matrix based metrics\n",
    "    :df_true: pd.DataFrame\n",
    "    :df_pred: pd.DataFrame\n",
    "    :k: int, \n",
    "    \"\"\"\n",
    "    # prepare dataset\n",
    "    df = df_true.set_index(['user_id', 'item_id']).join(df_pred.set_index(['user_id', 'item_id']))\n",
    "    df = df.sort_values(by = ['user_id', target_col])\n",
    "    df['users_watch_count'] = df.groupby(level = 'user_id')[target_col].transform(np.size)\n",
    "    df['cumulative_rank'] = df.groupby(level = 'user_id').cumcount() + 1\n",
    "    df['cumulative_rank'] = df['cumulative_rank'] / df[target_col]\n",
    "    \n",
    "    # params to calculate metrics\n",
    "    output = {}\n",
    "    num_of_users = df.index.get_level_values('user_id').nunique()\n",
    "\n",
    "    # calc metrics\n",
    "    df[f'hit@{k}'] = df[target_col] <= k\n",
    "    output[f'Precision@{k}'] = (df[f'hit@{k}'] / k).sum() / num_of_users\n",
    "    output[f'Recall@{k}'] = (df[f'hit@{k}'] / df['users_watch_count']).sum() / num_of_users\n",
    "    output[f'MAP@{k}'] = (df[\"cumulative_rank\"] / df[\"users_watch_count\"]).sum() / num_of_users\n",
    "    print(f'Calculated metrics for top {k}')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first-level only - LightFM\n",
    "lfm_metrics = calc_metrics(global_test, global_test_predictions)\n",
    "lfm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightFM + ReRanker\n",
    "full_pipeline_metrics = calc_metrics(global_test, cbm_global_test, target_col = 'cbm_rank')\n",
    "full_pipeline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cde2ff",
   "metadata": {},
   "source": [
    "Prettify both metrics calculation results for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d921dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = pd.concat(\n",
    "    [pd.DataFrame([lfm_metrics]),\n",
    "    pd.DataFrame([full_pipeline_metrics])],\n",
    "    ignore_index = True\n",
    ")\n",
    "metrics_table.index = ['LightFM', 'FullPipeline']\n",
    "\n",
    "# calc relative diff\n",
    "metrics_table = metrics_table.append(metrics_table.pct_change().iloc[-1].mul(100).rename('lift_by_ranker, %'))\n",
    "\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0445aa3",
   "metadata": {},
   "source": [
    "Thus, with a few number of features we could signifficantly improve our metrics using reranker.\n",
    "Just imagine how it can be improved if we add more features and fine tune the model\n",
    "\n",
    "# Source & further recommendations\n",
    "- [Kaggle Notebook for LightFM](https://www.kaggle.com/code/sharthz23/implicit-lightfm/notebook);\n",
    "- [Recommended course from MTS RecSys team on ods.ai](https://ods.ai/tracks/mts-recsys-df2020)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "source_map": [
   11,
   28,
   33,
   36,
   59,
   62,
   73,
   79,
   83,
   86,
   90,
   93,
   96,
   99,
   105,
   108,
   115,
   127,
   134,
   137,
   143,
   148,
   151,
   154,
   159,
   165,
   169,
   184,
   190,
   195,
   204,
   207,
   212,
   216,
   218,
   223,
   233,
   242,
   245,
   252,
   255,
   262,
   279,
   285,
   289,
   297,
   331,
   346,
   349,
   352,
   360,
   366,
   368,
   378,
   384,
   389,
   392,
   398,
   401,
   410,
   419,
   423,
   427,
   430,
   438,
   448,
   450,
   453,
   460,
   464,
   467,
   470,
   474,
   485,
   493,
   498,
   503,
   505,
   508,
   514,
   519,
   530,
   552,
   556,
   563,
   566,
   568,
   571,
   576,
   581,
   587,
   615,
   622,
   626,
   629,
   641
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}