{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa8f6b5",
   "metadata": {},
   "source": [
    "(chapter1_part5)=\n",
    "\n",
    "# Collaborative Filtering\n",
    "\n",
    "Collaborative filtering is a powerful method for recommendation systems used to predict user preferences or\n",
    "interests. It is based on the notion that people who have similar tastes and preferences in one domain are likely\n",
    "to have similar tastes and preferences in a different domain. The collaborative filtering technique seeks to identify\n",
    "users who have similar tastes and preferences, based on their past interactions, and then use those users'\n",
    "interactions of items to predict the relevance of similar items for the user. The goal of collaborative filtering is\n",
    "to use the opinions of other people to make predictions about a user’s preferences and interests.\n",
    "This is done by finding users who have similar tastes and preferences as the user in question, and then using\n",
    "those users’ ratings of items to make predictions about how the user would rate the same items.\n",
    "There are two main approaches to collaborative filtering: memory-based and model-based. \n",
    "\n",
    "## Memory-based Collaborative Filtering\n",
    "Memory-based collaborative filtering, also known as neighborhood-based collaborative filtering, is an approach\n",
    "that relies on finding similar users or items based on their behavior or preferences. The basic idea is to use\n",
    "the ratings or interactions of users with items to identify other users who have similar tastes, and then use\n",
    "the ratings of those similar users to make recommendations to a target user. One common approach in memory-based\n",
    "collaborative filtering is user-based collaborative filtering. In this approach, the similarity between users is\n",
    "calculated based on their ratings for items. A similarity metric such as the cosine similarity or Pearson correlation\n",
    "coefficient is often used to measure the similarity between two users. The similarity scores are then used to\n",
    "identify the most similar users to the target user. Once the most similar users are identified, their ratings\n",
    "for items are used to generate recommendations for the target user. Item-based collaborative filtering is another\n",
    "common approach in memory-based collaborative filtering. In this approach, the similarity between items is calculated\n",
    "based on the ratings of users who have rated both items. The similarity scores are then used to identify items that\n",
    "are similar to the items that the target user has already rated highly. Once similar items are identified,\n",
    "they are recommended to the target user. One advantage of memory-based collaborative filtering is that it is easy\n",
    "to implement and interpret. The algorithm is relatively simple and does not require a lot of computational resources.\n",
    "Additionally, memory-based collaborative filtering can be effective when there is a lot of data available and the\n",
    "user-item matrix is sparse. However, memory-based collaborative filtering also has several disadvantages.\n",
    "One major limitation is that it is prone to the cold-start problem, which occurs when there is not enough data\n",
    "available to identify similar users or items. Additionally, memory-based collaborative filtering can be\n",
    "computationally expensive when there are a large number of users or items.\n",
    "\n",
    "Let's consider an example with Pearson Correlation\n",
    "Say, we have a dataset that contains the ratings of four users on five movies. The data looks like this:\n",
    "\n",
    "|         | User A | User B | User C | User D |\n",
    "|-------- | -------- | ------- | ------- | -------- |\n",
    "|Movie 1 | 5 | 4 | 2 | 3 | \n",
    "|Movie 2 | 3 | 3 | 4 | 4 | \n",
    "|Movie 3 | 4 | 4 | 5 | 5 |\n",
    "|Movie 4 | 1 | 2 | 1 | 2 |\n",
    "|Movie 5 | 2 | 1 | 3 | 3 |\n",
    "\n",
    "\n",
    "To apply collaborative filtering, we can compute the similarity between each pair of users based on their \n",
    "ratings. The similarity is calculated using the Pearson Correlation Coefficient (PCC). The PCC is a measure\n",
    "of how well two sets of data are correlated, and it ranges from -1 (perfectly negatively correlated) to +1\n",
    "(perfectly positively correlated). For example, let’s assume that we want to find the similarity between\n",
    "User A and User B. The PCC is calculated by taking the average of the product of the ratings for each movie.\n",
    "So, let's get PCC for User A and User B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444d4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation for user A and B is: 0.8488746876271654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_a = [5, 3, 4, 1, 2]\n",
    "user_b = [4, 3, 4, 2, 1]\n",
    "\n",
    "print(f'Pearson Correlation for user A and B is: {np.corrcoef(user_a, user_b)[0, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3396f",
   "metadata": {},
   "source": [
    "It indicates that `User A` and `User B` have a strong positive correlation in their ratings.\n",
    "To find recommendations for `User A`, we can first identify the users who are most similar to `User A`.\n",
    "In this example, that would be `User B` and `User C` (check it out by calculating other pairs).\n",
    "Next, we can take the weighted average of the ratings from those users for the movies that `User A`\n",
    "has not yet been rated. For example, let’s assume that `User A` has not yet rated Movie 4. We can then take\n",
    "the weighted average of the ratings for Movie 4 from `User B` and `User C`.  `User B` rated Movie 4 a 2,\n",
    "and `User C` rated it a 1. We can then take the weighted average of those ratings, giving more weight \n",
    "to `User B` since they are more similar to `User A`. In this case, the weighted average would be around 2.\n",
    "Therefore, based on the ratings from other users, it is likely that `User A` would rate Movie 4 a 2.\n",
    "\n",
    "To wrap up, we can say that memory-based collaborative filtering is about calculating the similarity\n",
    "between rows or columns of the interaction matrix. In our example, we took columns a.k.a user similarities\n",
    "while we could take item-item similarities and use them as recommendation.\n",
    "\n",
    "\n",
    "## Model-based Collaborative Filtering\n",
    "Model-based collaborative filtering is an approach that uses machine learning algorithms to learn a model from \n",
    "the ratings or interactions of users with items. The model is then used to make predictions about the relevance of\n",
    "users for items that they have not yet interacted with. One common approach in model-based collaborative filtering\n",
    "is matrix factorization. In this approach, the user-item matrix is decomposed into two lower-dimensional matrices:\n",
    "a user matrix and an item matrix. The user matrix represents the latent preferences of users, and the item matrix\n",
    "represents the latent attributes of items. The dot product of the user and item matrices gives the predicted relevance\n",
    "for a user-item pair. Matrix factorization is typically performed using a technique called Singular Value Decomposition (SVD).\n",
    "An example of how it is computed is shown below. We have interactions data where rows represent\n",
    "users and columns their ratings/other interactions. Based on that we have found such matrices that would approximate\n",
    "this relationship from our interactions data. It is worth mentioning, that by SVD we only try to approximate rather\n",
    "than being able to restore the interactions matrix fully. Thus, we take *k* biggest singular values from the sigma (middle) matrix\n",
    "\n",
    "![](img/svd_example.png)\n",
    "*Toy example with SVD decomposition*\n",
    "\n",
    "Also, there are some peculiarities with SVD:\n",
    "- It is not that good to predict values to rank (if we consider it a regression problem)\n",
    "- Quite good for the generation of top-N candidates for further reranking:\n",
    "classically, for user and item embeddings we calculate the dot product and choose top-N by its value.\n",
    "\n",
    "However, SVD is computationally expensive and may not scale well to large datasets.\n",
    "Therefore, alternative techniques such as Alternating Least Squares (ALS) or modification for\n",
    "implicit target iALS, Stochastic Gradient Descent (SGD) are often used. Another common approach\n",
    "in model-based collaborative filtering is deep learning. In this approach, a neural network\n",
    "is used to learn a representation of users and items. The network takes as input the ratings\n",
    "or interactions of users with items and outputs a prediction of the rating for a user-item pair.\n",
    "Deep learning has the advantage of being able to capture complex patterns in the data and can be used\n",
    "to learn non-linear relationships between users and items. One of the popular examples is Extreme Deep Factorization machines (xDeepFM).\n",
    "\n",
    "One advantage of model-based collaborative filtering is that it can handle the cold-start problem by using the\n",
    "learned model to make predictions about items that have not yet been rated by users. Additionally, model-based\n",
    "collaborative filtering can be more accurate than memory-based collaborative filtering, especially when there are\n",
    "a large number of users and items. If we have enough data we can generate more accurate predictions minimizing our loss function\n",
    "\n",
    "However, model-based collaborative filtering also has some disadvantages. One major limitation is that it can be\n",
    "difficult to interpret the learned model and understand why certain recommendations are being made. Additionally,\n",
    "model-based collaborative filtering can be computationally expensive and may require a lot of computational resources,\n",
    "especially when using deep learning techniques. Another disadvantage of model-based collaborative filtering is that it\n",
    "requires a large amount of data to train the model effectively. This can be a challenge in some domains, where there\n",
    "may be a limited amount of data available. In these cases, memory-based collaborative filtering may be a better choice.\n",
    "However, there are several methods are available in Python for faster computations. Below, you can see several libraries\n",
    "that deal with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090373e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc797a",
   "metadata": {},
   "source": [
    "Besides, `SVD` we other matrix factorization techniques that use loss optimization. These are\n",
    "Alternating Least Squares (`ALS`) and implicit Alternating least squares  (`iALS`).\n",
    "\n",
    "\n",
    "`ALS` is an optimization algorithm used in collaborative filtering and designed to factorize a user-item\n",
    "interaction matrix into two lower-dimensional matrices, one representing users and the other representing\n",
    "items, while minimizing the reconstruction error. The algorithm works by alternating between fixing one\n",
    "matrix and optimizing the other. The loss function to train the model is the following:\n",
    "\n",
    "$\\begin{align}\n",
    "L_{explicit} = \\sum\\limits_{u,i \\in S}( r_{ui} - x_{u} y_{i}^{T} )^{2} + \\lambda \\big( \\sum\\limits_{u} \\left \\Vert x_{u} \\right \\Vert^{2} + \\sum\\limits_{i} \\left \\Vert y_{i} \\right \\Vert^{2} \\big)\n",
    "\\end{align}$\n",
    "\n",
    "Where:\n",
    "- $r_{ui}$ is the true rating given by user $u$ to the item $i$;\n",
    "- $x_u$ and $y_i$ are user u's and item i's latent factors, both are $1×d$ dimensional, where $d$ the number of latent factors that the user can specify;\n",
    "- $S$ was the set of all user-item ratings;\n",
    "- $\\lambda$ controls the regularization strength that prevents overfitting the user and item vectors\n",
    "\n",
    "As an example, let's say we have a user-item matrix where each row represents a user and each column represents an item.\n",
    "The entries in the matrix correspond to user-item interactions, such as ratings or watch history. To factorize\n",
    "this matrix using ALS, we first initialize the user and item matrices with random values. We then fix the item matrix and optimize the user matrix by minimizing the reconstruction error. We repeat this process by fixing the user matrix\n",
    "and optimizing the item matrix until the reconstruction error converges to a minimum.\n",
    "\n",
    "\n",
    "`iALS` is a modification of `ALS` that is designed to handle implicit feedback data, such as user clicks. In this case, the user-item interaction matrix only contains binary values indicating whether a user has interacted with an item or not. The algorithm works by incorporating a confidence weighting scheme that assigns higher weights to items that have been interacted with more frequently. As in the previous example, we repeat almost the same steps. However, in the process, we calculate the confidence weights for each item based on its interaction count. Then, we go on with minimizing the reconstruction error while taking into account the confidence weights.\n",
    "\n",
    "## Other Python Implementations\n",
    "To conclude, I want to mention several methods for implementation before focusing on the target `implicit` library.\n",
    "The first one is `implicit` which allows building models based on implicit targets. In addition,\n",
    "it has several frequently used models:\n",
    "- Item-to-Item KNN. Sometimes it is hard to generate recommendations based on user interaction due to the dynamic\n",
    "nature of their data (good real-time/near real-time data and model update is required). Thus, this method\n",
    "is a good kick-off point for candidate generation. KNN does not make any assumptions on the\n",
    "underlying data distribution but it relies on item feature similarity;\n",
    "- Logistic matrix factorization. It resembles the classic logit model where the collaborative filtering recommender tries to\n",
    "learn probabilistic distribution whether the user like recommendations;\n",
    "- implicit ALS. It is used when the amount of data is quite big and provides good performance by reducing\n",
    "the impact of missing data using confidence and preference metrics;\n",
    "- Bayesian Personalized Ranking. Its optimization relies on instance level - one item instead of item pairs. The\n",
    "the primary goal of the method is to provide a personalized list of recommendations directly\n",
    "\n",
    "Another one is the library we were going to use in the tutorial - `lightfm` (but in reality the maintenance of the\n",
    "library is not that good -- so I decided to switch to `implicit`). The main idea of the method\n",
    "is to generate feature vectors for both users and items by aggregating the values of features. The method assumes\n",
    "that the final `user embedding vector` is the sum of each of the user’s relevant side information\n",
    "vectors (which we called user features) and similarly `item embedding vector` is created.\n",
    "It is quite fast as developed in Cython. The model has several losses and optimizes parameters using Stochastic\n",
    "Gradient Descent (SGD) with options `adagrad` or `adadelta` - great explanation\n",
    "of the method can be found [here](https://code.themlsbook.com/chapter3/gradient_descent.html). The losses are:\n",
    "- Logistic;\n",
    "- Bayesian Personalized Ranking (BRP);\n",
    "- Weighted Approximate-Rank Pairwise (WARP);\n",
    "- k-os WARP\n",
    "\n",
    "Now, let's move on to Python implementation\n",
    "### 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85747c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links to shared data MovieLens\n",
    "# source on kaggle: https://www.kaggle.com/code/quangnhatbui/movie-recommender/data\n",
    "RATINGS_SMALL_URL = 'https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link'\n",
    "MOVIES_METADATA_URL = 'https://drive.google.com/file/d/19g6-apYbZb5D-wRj4L7aYKhxS-fDM4Fb/view?usp=share_link'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391ebac",
   "metadata": {},
   "source": [
    "### 1. Modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0402eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to make it available to download w/o SSL verification\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from itertools import islice, cycle, product\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009c81ce",
   "metadata": {},
   "source": [
    "#### 1. 1. Helper functions to avoid copy paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483b6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_gdrive(url):\n",
    "    \"\"\"\n",
    "    gets csv data from a given url (taken from file -> share -> copy link)\n",
    "    :url: example https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link\n",
    "    \"\"\"\n",
    "    file_id = url.split('/')[-2]\n",
    "    file_path = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427d68d",
   "metadata": {},
   "source": [
    "### 2. Main\n",
    "#### 2.1. Load Data\n",
    "`interactions` dataset shows list of movies that users watched, along with given ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e66a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interactions data\n",
    "interactions = read_csv_from_gdrive(RATINGS_SMALL_URL)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb53a1",
   "metadata": {},
   "source": [
    "`movies_metadata` dataset shows the list of movies existing on OKKO platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622a66ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "\n",
       "     original_title                                           overview  ...  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "2  Grumpier Old Men  A family wedding reignites the ancient feud be...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "2   1995-12-22          0.0   101.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline             title  video  \\\n",
       "0                                                NaN         Toy Story  False   \n",
       "1          Roll the dice and unleash the excitement!           Jumanji  False   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...  Grumpier Old Men  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          7.7     5415.0  \n",
       "1          6.9     2413.0  \n",
       "2          6.5       92.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information about films etc\n",
    "movies_metadata = read_csv_from_gdrive(MOVIES_METADATA_URL)\n",
    "movies_metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164d3bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to the same data type ids to filter\n",
    "movies_metadata['id'] = movies_metadata['id'].astype(str)\n",
    "interactions['movieId'] = interactions['movieId'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6bf90f",
   "metadata": {},
   "source": [
    "Filter only intersection of available movies in both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e36aee15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100004, 4) (44989, 4)\n"
     ]
    }
   ],
   "source": [
    "# leave only those films that intersect with each other\n",
    "interactions_filtered = interactions.loc[interactions['movieId'].isin(movies_metadata['id'])]\n",
    "print(interactions.shape, interactions_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ba397",
   "metadata": {},
   "source": [
    "#### 2.2 Data preparation\n",
    "To use implicit kNN method `fit` we need a sparse matrix in COOrdinate format. To achieve that we will use `scipy.sparse.coo_matrix` from scipy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4ce35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coo_matrix(\n",
    "        df: pd.DataFrame, \n",
    "        user_col: str,\n",
    "        item_col: str, \n",
    "        users_mapping: dict, \n",
    "        movies_mapping: dict,\n",
    "        weight_col: str = None\n",
    "        ):\n",
    "    if weight_col is None:\n",
    "        weights = np.ones(len(df), dtype=np.float32)\n",
    "    else:\n",
    "        weights = df[weight_col].astype(np.float32)\n",
    "    interaction_matrix = sp.coo_matrix((\n",
    "        weights, \n",
    "        (\n",
    "            df[user_col].map(users_mapping.get), \n",
    "            df[item_col].map(movies_mapping.get)\n",
    "        )\n",
    "    ))\n",
    "    return interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e581038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define users mapping\n",
    "users_inv_mapping = dict(enumerate(interactions_filtered['userId'].unique()))\n",
    "users_mapping = {v: k for k, v in users_inv_mapping.items()}\n",
    "len(users_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3663e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define movies mapping\n",
    "movies_inv_mapping = dict(enumerate(interactions_filtered['movieId'].unique()))\n",
    "movies_mapping = {v: k for k, v in movies_inv_mapping.items()}\n",
    "len(movies_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bed4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train set on the whole interactions dataset (as HW you will have to split into test and train for evaluation)\n",
    "train_mat = get_coo_matrix(\n",
    "    interactions_filtered,\n",
    "    user_col = 'userId',\n",
    "    item_col = 'movieId',\n",
    "    users_mapping = users_mapping,\n",
    "    movies_mapping = movies_mapping\n",
    "    ).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530a400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<671x2830 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 44989 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550bcf01",
   "metadata": {},
   "source": [
    "#### 2.3. Model Training & Evaluation\n",
    "In [`implicit`](https://pypi.org/project/implicit/), there are various models and can be groupped into:\n",
    "- Item-to-Item: KNN based on various similarities - CosineRecommender, BM25Recommender, TFIDFRecommender\n",
    "- implicit ALS;\n",
    "- Logistic Matrix Factorization;\n",
    "- Bayesian Personalized Ranking (BPR)\n",
    "\n",
    "##### 2.3.1. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b2073b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import (\n",
    "    CosineRecommender,\n",
    "    BM25Recommender,\n",
    "    TFIDFRecommender\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99342bd",
   "metadata": {},
   "source": [
    "Note that in item-to-item models we need to provide matrix in the form of item-user by transposing initial COO matrix user-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3596076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/671 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 671/671 [00:00<00:00, 45991.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "cosine_model = CosineRecommender(K = 20)\n",
    "cosine_model.fit(train_mat.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ab0d0",
   "metadata": {},
   "source": [
    "##### 2.3.2. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af9a053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekko for user 1, row number in matrix - 0\n"
     ]
    }
   ],
   "source": [
    "# let's make sense-check\n",
    "top_N = 10\n",
    "user_id = interactions_filtered['userId'].iloc[0]\n",
    "row_id = users_mapping[user_id]\n",
    "print(f'Rekko for user {user_id}, row number in matrix - {row_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5779eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapper for movieId and title names\n",
    "movie_name_mapper = dict(zip(movies_metadata['id'], movies_metadata['original_title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63df8b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>inv_movie_id</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>653.0</td>\n",
       "      <td>0.861587</td>\n",
       "      <td>653</td>\n",
       "      <td>74458</td>\n",
       "      <td>Mere Brother Ki Dulhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129.0</td>\n",
       "      <td>0.844531</td>\n",
       "      <td>129</td>\n",
       "      <td>1994</td>\n",
       "      <td>The Most Dangerous Game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>606.0</td>\n",
       "      <td>0.654064</td>\n",
       "      <td>606</td>\n",
       "      <td>8011</td>\n",
       "      <td>Highlander III: The Sorcerer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294.0</td>\n",
       "      <td>0.625141</td>\n",
       "      <td>294</td>\n",
       "      <td>70</td>\n",
       "      <td>Million Dollar Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>337.0</td>\n",
       "      <td>0.593856</td>\n",
       "      <td>337</td>\n",
       "      <td>170</td>\n",
       "      <td>28 Days Later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>648.0</td>\n",
       "      <td>0.577499</td>\n",
       "      <td>648</td>\n",
       "      <td>68954</td>\n",
       "      <td>Longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>579.0</td>\n",
       "      <td>0.571681</td>\n",
       "      <td>579</td>\n",
       "      <td>5956</td>\n",
       "      <td>Joshua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>399.0</td>\n",
       "      <td>0.561442</td>\n",
       "      <td>399</td>\n",
       "      <td>1088</td>\n",
       "      <td>Whale Rider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>278.0</td>\n",
       "      <td>0.561442</td>\n",
       "      <td>278</td>\n",
       "      <td>1584</td>\n",
       "      <td>School of Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.557086</td>\n",
       "      <td>150</td>\n",
       "      <td>2100</td>\n",
       "      <td>The Last Castle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_id  similarity  inv_movie_id movieId                         title\n",
       "0   653.0    0.861587           653   74458        Mere Brother Ki Dulhan\n",
       "1   129.0    0.844531           129    1994       The Most Dangerous Game\n",
       "2   606.0    0.654064           606    8011  Highlander III: The Sorcerer\n",
       "3   294.0    0.625141           294      70           Million Dollar Baby\n",
       "4   337.0    0.593856           337     170                 28 Days Later\n",
       "5   648.0    0.577499           648   68954                     Longitude\n",
       "6   579.0    0.571681           579    5956                        Joshua\n",
       "7   399.0    0.561442           399    1088                   Whale Rider\n",
       "8   278.0    0.561442           278    1584                School of Rock\n",
       "9   150.0    0.557086           150    2100               The Last Castle"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = cosine_model.recommend(\n",
    "    row_id,\n",
    "    train_mat,\n",
    "    N = top_N,\n",
    "    filter_already_liked_items = True\n",
    "    )\n",
    "recs = pd.DataFrame(recs).T.rename(columns = {0: 'col_id', 1: 'similarity'})\n",
    "recs['inv_movie_id'] = recs['col_id'].astype(int)\n",
    "recs['movieId'] = recs['inv_movie_id'].map(movies_inv_mapping.get)\n",
    "recs['title'] = recs['movieId'].map(movie_name_mapper)\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd5b2c",
   "metadata": {},
   "source": [
    "## Hybrid Approaches\n",
    "In practice, many recommender systems use a hybrid approach that combines both memory-based and model-based\n",
    "collaborative filtering. In a hybrid approach, the strengths of both approaches are leveraged to improve the\n",
    "accuracy and performance of the recommender system. One common approach in hybrid collaborative filtering is\n",
    "to use a memory-based approach to generate initial recommendations and then refine the recommendations using\n",
    "a model-based approach. This approach can be effective in situations where there is not enough data to train\n",
    "a model effectively but there is enough data to identify similar users or items using a memory-based approach.\n",
    "Another approach is to use a model-based approach to generate initial recommendations and then refine the\n",
    "recommendations using a memory-based approach. This approach can be effective in situations where the user-item\n",
    "matrix is very sparse and a model-based approach is needed to make accurate predictions.\n",
    "\n",
    "# Source & further recommendations\n",
    "- [Easy intro to Collaborative Filtering by Google](https://developers.google.com/machine-learning/recommendation/collaborative/basics)\n",
    "- Series of articles on Medium: [Part 1](https://towardsdatascience.com/collaborative-filtering-and-embeddings-part-1-63b00b9739ce),\n",
    "[Part 2](https://towardsdatascience.com/collaborative-filtering-and-embeddings-part-2-919da17ecefb)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "source_map": [
   11,
   67,
   74,
   135,
   139,
   198,
   203,
   205,
   219,
   221,
   232,
   237,
   241,
   244,
   250,
   254,
   256,
   260,
   265,
   288,
   295,
   302,
   313,
   315,
   326,
   332,
   334,
   338,
   342,
   350,
   355,
   367
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}